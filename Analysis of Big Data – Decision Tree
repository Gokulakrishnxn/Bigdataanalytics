import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             confusion_matrix, classification_report, roc_curve, auc, 
                             roc_auc_score)
import warnings
warnings.filterwarnings('ignore')

# Set visualization style
sns.set_style("whitegrid")
plt.rcParams['figure.facecolor'] = 'white'

print("=" * 110)
print("DECISION TREE ANALYSIS - CUSTOMER CHURN PREDICTION FOR BIG DATA")
print("=" * 110)

# Generate realistic Telco Customer Churn dataset
np.random.seed(42)

n_customers = 7043

# Generate features
customer_ids = [f'C{str(i).zfill(6)}' for i in range(1, n_customers + 1)]
gender = np.random.choice(['Male', 'Female'], n_customers, p=[0.5, 0.5])
senior_citizen = np.random.choice([0, 1], n_customers, p=[0.84, 0.16])
partner = np.random.choice(['Yes', 'No'], n_customers, p=[0.48, 0.52])
dependents = np.random.choice(['Yes', 'No'], n_customers, p=[0.3, 0.7])

# Tenure (months with company)
tenure = np.random.choice(range(1, 73), n_customers)

# Services
phone_service = np.random.choice(['Yes', 'No'], n_customers, p=[0.9, 0.1])
internet_service = np.random.choice(['DSL', 'Fiber optic', 'No'], n_customers, p=[0.34, 0.44, 0.22])
online_security = np.random.choice(['Yes', 'No', 'No internet service'], n_customers, p=[0.28, 0.5, 0.22])
tech_support = np.random.choice(['Yes', 'No', 'No internet service'], n_customers, p=[0.29, 0.49, 0.22])
streaming_tv = np.random.choice(['Yes', 'No', 'No internet service'], n_customers, p=[0.38, 0.4, 0.22])

# Contract and billing
contract = np.random.choice(['Month-to-month', 'One year', 'Two year'], n_customers, p=[0.55, 0.21, 0.24])
paperless_billing = np.random.choice(['Yes', 'No'], n_customers, p=[0.59, 0.41])
payment_method = np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], 
                                  n_customers, p=[0.34, 0.23, 0.22, 0.21])

# Monthly charges based on services
monthly_charges = np.zeros(n_customers)
monthly_charges += (phone_service == 'Yes') * np.random.uniform(20, 30, n_customers)
monthly_charges += (internet_service == 'Fiber optic') * np.random.uniform(40, 60, n_customers)
monthly_charges += (internet_service == 'DSL') * np.random.uniform(20, 35, n_customers)
monthly_charges += (streaming_tv == 'Yes') * np.random.uniform(10, 15, n_customers)
monthly_charges = np.round(monthly_charges, 2)

# Total charges
total_charges = np.round(monthly_charges * tenure + np.random.uniform(-100, 100, n_customers), 2)
total_charges = np.maximum(total_charges, monthly_charges)  # Ensure total >= monthly

# Churn (target variable) - influenced by multiple factors
churn_prob = np.zeros(n_customers)
churn_prob += (contract == 'Month-to-month') * 0.35
churn_prob += (contract == 'One year') * 0.1
churn_prob += (contract == 'Two year') * 0.03
churn_prob += (tenure < 12) * 0.25
churn_prob += (senior_citizen == 1) * 0.1
churn_prob += (internet_service == 'Fiber optic') * 0.15
churn_prob += (tech_support == 'No') * 0.1
churn_prob += (monthly_charges > 70) * 0.15
churn_prob += (paperless_billing == 'Yes') * 0.05
churn_prob = np.clip(churn_prob, 0, 1)
churn = (np.random.random(n_customers) < churn_prob).astype(int)
churn = np.where(churn == 1, 'Yes', 'No')

# Create DataFrame
df = pd.DataFrame({
    'CustomerID': customer_ids,
    'Gender': gender,
    'SeniorCitizen': senior_citizen,
    'Partner': partner,
    'Dependents': dependents,
    'Tenure': tenure,
    'PhoneService': phone_service,
    'InternetService': internet_service,
    'OnlineSecurity': online_security,
    'TechSupport': tech_support,
    'StreamingTV': streaming_tv,
    'Contract': contract,
    'PaperlessBilling': paperless_billing,
    'PaymentMethod': payment_method,
    'MonthlyCharges': monthly_charges,
    'TotalCharges': total_charges,
    'Churn': churn
})

print("\n1. DATASET OVERVIEW")
print("-" * 110)
print(f"Total Customers: {len(df)}")
print(f"Total Features: {df.shape[1]}")
print(f"Churn Rate: {(df['Churn'] == 'Yes').sum()/len(df)*100:.2f}%")
print(f"Retained Customers: {(df['Churn'] == 'No').sum()} ({(df['Churn'] == 'No').sum()/len(df)*100:.2f}%)")
print(f"\nFirst 5 Records:")
print(df.head().to_string())

print("\n2. STATISTICAL SUMMARY")
print("-" * 110)
print(df.describe().to_string())

print("\n3. CHURN DISTRIBUTION BY KEY FACTORS")
print("-" * 110)
print("Churn Rate by Contract Type:")
print(df.groupby('Contract')['Churn'].apply(lambda x: (x == 'Yes').sum() / len(x) * 100).to_string())
print("\nChurn Rate by Internet Service:")
print(df.groupby('InternetService')['Churn'].apply(lambda x: (x == 'Yes').sum() / len(x) * 100).to_string())

# ==================== DATA PREPROCESSING ====================
print("\n4. DATA PREPROCESSING")
print("-" * 110)

# Separate features and target
X = df.drop(['CustomerID', 'Churn'], axis=1)
y = df['Churn']

# Encode categorical variables
label_encoders = {}
categorical_cols = X.select_dtypes(include=['object']).columns

print(f"Categorical features to encode: {list(categorical_cols)}")
print(f"Original shape: {X.shape}")

for col in categorical_cols:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col])
    label_encoders[col] = le

# Encode target variable
y = (y == 'Yes').astype(int)

print(f"Target variable encoded: No=0, Yes=1")
print(f"Class distribution: No={sum(y==0)}, Yes={sum(y==1)}")

# ==================== TRAIN-TEST SPLIT ====================
print("\n5. TRAIN-TEST SPLIT")
print("-" * 110)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

print(f"Training set size: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)")
print(f"Testing set size: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)")
print(f"Training set churn rate: {y_train.mean()*100:.2f}%")
print(f"Testing set churn rate: {y_test.mean()*100:.2f}%")

# ==================== DECISION TREE MODEL - INITIAL ====================
print("\n6. INITIAL DECISION TREE MODEL (NO PRUNING)")
print("-" * 110)

dt_initial = DecisionTreeClassifier(random_state=42)
dt_initial.fit(X_train, y_train)

# Training predictions
y_train_pred_initial = dt_initial.predict(X_train)
train_accuracy_initial = accuracy_score(y_train, y_train_pred_initial)

# Testing predictions
y_test_pred_initial = dt_initial.predict(X_test)
test_accuracy_initial = accuracy_score(y_test, y_test_pred_initial)

print(f"Tree depth: {dt_initial.get_depth()}")
print(f"Number of leaves: {dt_initial.get_n_leaves()}")
print(f"Number of nodes: {dt_initial.tree_.node_count}")
print(f"\nTraining Accuracy: {train_accuracy_initial*100:.2f}%")
print(f"Testing Accuracy: {test_accuracy_initial*100:.2f}%")
print(f"Overfitting Gap: {(train_accuracy_initial - test_accuracy_initial)*100:.2f}%")

# ==================== HYPERPARAMETER TUNING ====================
print("\n7. HYPERPARAMETER TUNING WITH GRID SEARCH")
print("-" * 110)

param_grid = {
    'max_depth': [3, 5, 7, 10, 15, None],
    'min_samples_split': [2, 5, 10, 20],
    'min_samples_leaf': [1, 2, 4, 8],
    'criterion': ['gini', 'entropy']
}

grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), 
                          param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)

print(f"Best parameters: {grid_search.best_params_}")
print(f"Best cross-validation score: {grid_search.best_score_*100:.2f}%")

# ==================== OPTIMIZED DECISION TREE ====================
print("\n8. OPTIMIZED DECISION TREE MODEL")
print("-" * 110)

dt_optimized = grid_search.best_estimator_

# Training predictions
y_train_pred = dt_optimized.predict(X_train)
train_accuracy = accuracy_score(y_train, y_train_pred)

# Testing predictions
y_test_pred = dt_optimized.predict(X_test)
test_accuracy = accuracy_score(y_test, y_test_pred)

print(f"Tree depth: {dt_optimized.get_depth()}")
print(f"Number of leaves: {dt_optimized.get_n_leaves()}")
print(f"Number of nodes: {dt_optimized.tree_.node_count}")
print(f"\nTraining Accuracy: {train_accuracy*100:.2f}%")
print(f"Testing Accuracy: {test_accuracy*100:.2f}%")
print(f"Overfitting Gap: {(train_accuracy - test_accuracy)*100:.2f}%")
print(f"Improvement from initial model: {(test_accuracy - test_accuracy_initial)*100:.2f}%")

# ==================== MODEL EVALUATION METRICS ====================
print("\n9. COMPREHENSIVE MODEL EVALUATION")
print("-" * 110)

# Calculate metrics
precision = precision_score(y_test, y_test_pred)
recall = recall_score(y_test, y_test_pred)
f1 = f1_score(y_test, y_test_pred)
roc_auc = roc_auc_score(y_test, dt_optimized.predict_proba(X_test)[:, 1])

print(f"Accuracy: {test_accuracy*100:.2f}%")
print(f"Precision: {precision*100:.2f}%")
print(f"Recall (Sensitivity): {recall*100:.2f}%")
print(f"F1-Score: {f1*100:.2f}%")
print(f"ROC-AUC Score: {roc_auc:.4f}")

# Confusion Matrix
cm = confusion_matrix(y_test, y_test_pred)
print(f"\nConfusion Matrix:")
print(f"                 Predicted No  Predicted Yes")
print(f"Actual No        {cm[0,0]:12d}  {cm[0,1]:13d}")
print(f"Actual Yes       {cm[1,0]:12d}  {cm[1,1]:13d}")

# Classification Report
print(f"\nDetailed Classification Report:")
print(classification_report(y_test, y_test_pred, target_names=['No Churn', 'Churn']))

# ==================== FEATURE IMPORTANCE ====================
print("\n10. FEATURE IMPORTANCE ANALYSIS")
print("-" * 110)

feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': dt_optimized.feature_importances_
}).sort_values('Importance', ascending=False)

print("Top 10 Most Important Features:")
print(feature_importance.head(10).to_string(index=False))

print(f"\nTotal features used by the tree: {sum(dt_optimized.feature_importances_ > 0)}")
print(f"Features not used: {sum(dt_optimized.feature_importances_ == 0)}")

# ==================== CROSS-VALIDATION ====================
print("\n11. CROSS-VALIDATION ANALYSIS")
print("-" * 110)

cv_scores = cross_val_score(dt_optimized, X_train, y_train, cv=5, scoring='accuracy')
print(f"5-Fold Cross-Validation Scores: {[f'{score*100:.2f}%' for score in cv_scores]}")
print(f"Mean CV Score: {cv_scores.mean()*100:.2f}%")
print(f"Standard Deviation: {cv_scores.std()*100:.2f}%")

# ==================== COMPREHENSIVE VISUALIZATIONS ====================
fig = plt.figure(figsize=(20, 16))

# Plot 1: Decision Tree Visualization (Pruned)
ax1 = plt.subplot(3, 3, 1)
plot_tree(dt_optimized, max_depth=3, feature_names=X.columns, 
          class_names=['No Churn', 'Churn'], filled=True, rounded=True, 
          fontsize=7, ax=ax1)
ax1.set_title('1. Decision Tree Structure (Max Depth=3 for Visibility)', 
              fontsize=11, fontweight='bold')

# Plot 2: Feature Importance
ax2 = plt.subplot(3, 3, 2)
top_features = feature_importance.head(10)
ax2.barh(range(len(top_features)), top_features['Importance'], color='skyblue', edgecolor='black')
ax2.set_yticks(range(len(top_features)))
ax2.set_yticklabels(top_features['Feature'])
ax2.set_xlabel('Importance', fontsize=10)
ax2.set_title('2. Top 10 Feature Importance', fontsize=11, fontweight='bold')
ax2.invert_yaxis()
ax2.grid(axis='x', alpha=0.3)

# Plot 3: Confusion Matrix Heatmap
ax3 = plt.subplot(3, 3, 3)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax3,
            xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])
ax3.set_xlabel('Predicted', fontsize=10)
ax3.set_ylabel('Actual', fontsize=10)
ax3.set_title('3. Confusion Matrix', fontsize=11, fontweight='bold')

# Plot 4: Model Comparison (Initial vs Optimized)
ax4 = plt.subplot(3, 3, 4)
models = ['Initial\nModel', 'Optimized\nModel']
train_scores = [train_accuracy_initial*100, train_accuracy*100]
test_scores = [test_accuracy_initial*100, test_accuracy*100]
x = np.arange(len(models))
width = 0.35
bars1 = ax4.bar(x - width/2, train_scores, width, label='Training', color='lightblue', edgecolor='black')
bars2 = ax4.bar(x + width/2, test_scores, width, label='Testing', color='lightcoral', edgecolor='black')
ax4.set_ylabel('Accuracy (%)', fontsize=10)
ax4.set_title('4. Model Performance Comparison', fontsize=11, fontweight='bold')
ax4.set_xticks(x)
ax4.set_xticklabels(models)
ax4.legend()
ax4.grid(axis='y', alpha=0.3)
for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.1f}%', ha='center', va='bottom', fontsize=8)

# Plot 5: ROC Curve
ax5 = plt.subplot(3, 3, 5)
y_pred_proba = dt_optimized.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
ax5.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')
ax5.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')
ax5.set_xlabel('False Positive Rate', fontsize=10)
ax5.set_ylabel('True Positive Rate', fontsize=10)
ax5.set_title('5. ROC Curve', fontsize=11, fontweight='bold')
ax5.legend()
ax5.grid(True, alpha=0.3)

# Plot 6: Precision-Recall Trade-off
ax6 = plt.subplot(3, 3, 6)
metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
scores = [test_accuracy*100, precision*100, recall*100, f1*100]
colors = ['#4CAF50', '#2196F3', '#FF9800', '#9C27B0']
bars = ax6.bar(metrics, scores, color=colors, edgecolor='black')
ax6.set_ylabel('Score (%)', fontsize=10)
ax6.set_title('6. Model Performance Metrics', fontsize=11, fontweight='bold')
ax6.set_ylim([0, 100])
ax6.grid(axis='y', alpha=0.3)
for bar, score in zip(bars, scores):
    ax6.text(bar.get_x() + bar.get_width()/2., bar.get_height(),
            f'{score:.1f}%', ha='center', va='bottom', fontsize=9)

# Plot 7: Tree Depth vs Accuracy
ax7 = plt.subplot(3, 3, 7)
depths = [3, 5, 7, 10, 15, 20]
train_accs = []
test_accs = []
for depth in depths:
    dt_temp = DecisionTreeClassifier(max_depth=depth, random_state=42)
    dt_temp.fit(X_train, y_train)
    train_accs.append(accuracy_score(y_train, dt_temp.predict(X_train))*100)
    test_accs.append(accuracy_score(y_test, dt_temp.predict(X_test))*100)
ax7.plot(depths, train_accs, 'o-', linewidth=2, markersize=8, label='Training', color='blue')
ax7.plot(depths, test_accs, 's-', linewidth=2, markersize=8, label='Testing', color='red')
ax7.set_xlabel('Max Depth', fontsize=10)
ax7.set_ylabel('Accuracy (%)', fontsize=10)
ax7.set_title('7. Tree Depth vs Accuracy', fontsize=11, fontweight='bold')
ax7.legend()
ax7.grid(True, alpha=0.3)

# Plot 8: Cross-Validation Scores
ax8 = plt.subplot(3, 3, 8)
cv_folds = [f'Fold {i+1}' for i in range(5)]
bars = ax8.bar(cv_folds, cv_scores*100, color='teal', edgecolor='black')
ax8.axhline(y=cv_scores.mean()*100, color='red', linestyle='--', linewidth=2, 
            label=f'Mean: {cv_scores.mean()*100:.2f}%')
ax8.set_ylabel('Accuracy (%)', fontsize=10)
ax8.set_title('8. Cross-Validation Results', fontsize=11, fontweight='bold')
ax8.legend()
ax8.grid(axis='y', alpha=0.3)
for bar, score in zip(bars, cv_scores*100):
    ax8.text(bar.get_x() + bar.get_width()/2., bar.get_height(),
            f'{score:.1f}%', ha='center', va='bottom', fontsize=9)

# Plot 9: Churn Distribution
ax9 = plt.subplot(3, 3, 9)
churn_counts = df['Churn'].value_counts()
colors_pie = ['#66b3ff', '#ff9999']
explode = (0.05, 0.05)
wedges, texts, autotexts = ax9.pie(churn_counts.values, labels=['No Churn', 'Churn'], 
                                     autopct='%1.1f%%', startangle=90, colors=colors_pie, 
                                     explode=explode, shadow=True)
for autotext in autotexts:
    autotext.set_color('black')
    autotext.set_fontsize(10)
    autotext.set_weight('bold')
ax9.set_title('9. Overall Churn Distribution', fontsize=11, fontweight='bold')

plt.tight_layout()
plt.savefig('decision_tree_comprehensive_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# ==================== BUSINESS INSIGHTS ====================
print("\n12. KEY BUSINESS INSIGHTS AND RECOMMENDATIONS")
print("-" * 110)

print("\nHigh-Risk Churn Indicators:")
for idx, row in feature_importance.head(5).iterrows():
    print(f"  • {row['Feature']}: {row['Importance']*100:.2f}% importance")

print("\nActionable Recommendations:")
print("  1. Focus retention efforts on month-to-month contract customers")
print("  2. Implement loyalty programs for customers with low tenure (<12 months)")
print("  3. Provide incentives for customers to upgrade to longer-term contracts")
print("  4. Enhance technical support services to reduce churn")
print("  5. Monitor and engage customers with high monthly charges proactively")
print("  6. Create targeted campaigns for fiber optic internet customers")

# Sample predictions
print("\n13. SAMPLE CHURN PREDICTIONS")
print("-" * 110)
sample_customers = X_test.head(5)
sample_predictions = dt_optimized.predict(sample_customers)
sample_probabilities = dt_optimized.predict_proba(sample_customers)

print("CustomerID | Actual Churn | Predicted | Churn Probability")
print("-" * 70)
for i in range(5):
    actual = 'Yes' if y_test.iloc[i] == 1 else 'No'
    predicted = 'Yes' if sample_predictions[i] == 1 else 'No'
    prob = sample_probabilities[i][1] * 100
    print(f"Customer {i+1}  |     {actual:3s}      |    {predicted:3s}    |      {prob:.2f}%")

print("\n" + "=" * 110)
print("DECISION TREE ANALYSIS COMPLETE")
print("=" * 110)
print("\nVisualization saved as 'decision_tree_comprehensive_analysis.png'")
print("\nKey Achievements:")
print("  • Built interpretable decision tree model for churn prediction")
print("  • Achieved optimized accuracy through hyperparameter tuning")
print("  • Identified critical features influencing customer churn")
print("  • Provided actionable business recommendations for retention strategies")
print("  • Created transparent, explainable AI model for stakeholder understanding")
